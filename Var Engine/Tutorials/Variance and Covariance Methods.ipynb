{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import math\n",
    "import statistics\n",
    "from scipy.stats import norm, t\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annual VaR and CVar Engine Utilizng the Variance and Covariance Method\n",
    "list_assets = [\"HSBC\", \"BCS\", \"TSLA\", \"NVDA\"]\n",
    "dict_assets = {}\n",
    "initial_portfolio = 100000\n",
    "time = 250\n",
    "\n",
    "def hour_wiper(df):\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_grabber(tickers, assets):\n",
    "    #Function designed to take any ticker and grab annual data\n",
    "    for x in tickers:\n",
    "        try: \n",
    "            \n",
    "            ticker = yf.Ticker(x)\n",
    "            ticker_data = ticker.history(period = \"1y\", interval = \"1d\")\n",
    "            ticker_data = hour_wiper(ticker_data)\n",
    "            if not ticker_data.empty:\n",
    "                assets[x] = ticker_data\n",
    "            else:\n",
    "                print(f\"The associated data for {x} is empty\")\n",
    "        except Exception as e:\n",
    "            print(f\"There was an error in fetching {x} data\")\n",
    "            \n",
    "    return assets\n",
    "\n",
    "def returns(dict_assets):\n",
    "    #Calculates daily returns of each asset in the portfolio and puts them into a seperate dataframe\n",
    "    for x in dict_assets:\n",
    "        df_common = dict_assets[x]    \n",
    "        df_common[\"Returns\"] = df_common[\"Close\"].pct_change()\n",
    "        df_common = df_common.dropna()        \n",
    "        dict_assets[x] = df_common\n",
    "    \n",
    "    dict_returns = {}    \n",
    "    for x in dict_assets:\n",
    "        df_common = dict_assets[x]\n",
    "        series_returns = df_common[\"Returns\"]\n",
    "        dict_returns[x] = series_returns\n",
    "        \n",
    "    df_returns = pd.concat(dict_returns.values(), axis = 1, keys=dict_returns)\n",
    "    mean_returns = df_returns.mean()\n",
    "    \n",
    "    return dict_assets, df_returns, mean_returns\n",
    "\n",
    "def weights(dict_assets, list_weights):\n",
    "    #Takes weights and inserts them into dataframes of each asset as a column \n",
    "    \n",
    "    list_counter = 0\n",
    "    if isinstance(list_weights, list):\n",
    "        for x in list_weights:\n",
    "            x = float(x)\n",
    "            x = x/100\n",
    "            list_weights[list_counter] = x\n",
    "            list_counter += 1\n",
    "        array_weights = np.array(list_weights)\n",
    "    else:\n",
    "        raise TypeError(\"the expected data structure for the weights is a list\")\n",
    "    \n",
    "    if np.sum(array_weights) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"The sum of your weights does not equal to 1\")\n",
    "    \n",
    "    weights_counter = 0\n",
    "    if  len(array_weights) == len(dict_assets):\n",
    "        for key in dict_assets:\n",
    "            df_common = dict_assets[key]\n",
    "            df_common[\"Weights\"] = list_weights[weights_counter]\n",
    "            df_common = df_common.dropna()\n",
    "            dict_assets[key] = df_common\n",
    "            weights_counter += 1\n",
    "    else:\n",
    "        print(f\"The number of assets and weights do not match up, please try again\")\n",
    "    \n",
    "    return dict_assets, array_weights\n",
    "\n",
    "def portfolio(dict_assets):\n",
    "    #Assembles the portfolio into a singular dataframe\n",
    "    df_portfolio = pd.concat(dict_assets.values(), axis = 1, keys=dict_assets.keys())\n",
    "    df_portfolio = df_portfolio.reset_index()\n",
    "\n",
    "    return df_portfolio\n",
    "    \n",
    "def portfolio_return(df_portfolio, df_returns, array_weights):\n",
    "    #Calculates the daily returns of the portfolio given the weights\n",
    "        \n",
    "    series_portfolio_return = df_returns.dot(array_weights)\n",
    "    df_portfolio[\"Portfolio Returns\"] = series_portfolio_return\n",
    "    \n",
    "    return df_portfolio, df_returns, series_portfolio_return\n",
    "    \n",
    "def covariance_matrix(dict_assets, df_returns):\n",
    "    #Finds the covariance between the returns of each asset in the portfolio        \n",
    "    df_cov = df_returns.cov()\n",
    "    \n",
    "    return df_cov\n",
    "  \n",
    "def portfolio_variance_calculator(df_cov, array_weights):\n",
    "    #Find portfolio variance given covariance matrix and weights of the portfolio\n",
    "    array_portfolio_variance = np.dot(array_weights.T, np.dot(df_cov, array_weights))\n",
    "    float_portfolio_variance = float(array_portfolio_variance)\n",
    "    return float_portfolio_variance  \n",
    "    \n",
    "def portfolio_std(float_portfolio_variance):\n",
    "    #Multiply by the square root of time to annualize the volatility\n",
    "    float_portfolio_std = (math.sqrt(float_portfolio_variance))*np.sqrt(time)\n",
    "    \n",
    "    return float_portfolio_std\n",
    "    \n",
    "def portfolio_mean_return(mean_returns, array_weights):\n",
    "    #Multiply by the number of trading days to annualize average portfolio return\n",
    "    P_returns = np.sum(mean_returns*array_weights)*time\n",
    "\n",
    "    \n",
    "    return P_returns\n",
    "\n",
    "def Var_Parametric(portfolio_return, std, distribution, dof = 6):\n",
    "    \"\"\"Calculate the portfolio VaR Given a distribution with known parameters\"\"\"\n",
    "    list_alpha = [0.9, 0.95, 0.975, 0.99]\n",
    "    dict_VaR = {}\n",
    "    \n",
    "    for x in list_alpha:\n",
    "        if distribution == \"normal\":\n",
    "            VaR = round((norm.ppf(1-x) * std - portfolio_return)*initial_portfolio, 2)*-1\n",
    "        elif distribution == \"t-distribution\":\n",
    "            nu = dof\n",
    "            VaR = round((np.sqrt((nu-2)/nu) * t.ppf(1-x, nu)* std - portfolio_return * initial_portfolio, 2))*-1\n",
    "        else:\n",
    "            raise TypeError(\"Expected distribution to be normal or t-distribution\")\n",
    "        dict_VaR[x] = VaR\n",
    "    print(f\"Annual Var with associated confidence levels: {dict_VaR}\")    \n",
    "        \n",
    "    return dict_VaR\n",
    "\n",
    "def CVar_Parametric(portfolio_return, std, distribution = \"normal\", dof = 6):\n",
    "    \"\"\"Calculate the portfolio CVaR Given a distribution with known parameters\"\"\"\n",
    "    list_alpha = [0.9, 0.95, 0.975, 0.99]\n",
    "    dict_CVaR = {}\n",
    "    \n",
    "    for x in list_alpha:\n",
    "        if distribution == \"normal\":\n",
    "            CVaR = round(((1-x)**-1 * norm.pdf(norm.ppf(1-x))* std - portfolio_return)*initial_portfolio,2)*-1\n",
    "        elif distribution == \"t-distribution\":\n",
    "            nu = dof\n",
    "            x_anu = t.ppf(1-x, nu)\n",
    "            CVaR = round((-1/(1-x) * (1-nu)**-1 * (nu-2+x_anu**2) * t.ppf(x_anu, nu)* std - portfolio_return)*initial_portfolio, 2)*-1\n",
    "        else:\n",
    "            raise TypeError(\"Expected distribution to be normal or t-distribution\")\n",
    "        dict_CVaR[x] = CVaR\n",
    "    print(f\"Annual CVar with associated confidence levels: {dict_CVaR}\")    \n",
    "        \n",
    "    return dict_CVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_weights = [\"20\", \"30\", \"40\", \"10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual Var with associated confidence levels: {0.9: 55520.33, 0.95: 66019.72, 0.975: 75126.37, 0.99: 85714.82}\n",
      "Annual CVar with associated confidence levels: {0.9: -32235.16, 0.95: -41128.51, 0.975: -49078.58, 0.99: -58540.73}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.9: -32235.16, 0.95: -41128.51, 0.975: -49078.58, 0.99: -58540.73}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grabber(list_assets, dict_assets)\n",
    "dict_assets, df_returns, mean_returns = returns(dict_assets)\n",
    "df_portfolio = portfolio(dict_assets)\n",
    "dict_assets, array_weights = weights(dict_assets, list_weights)\n",
    "df_portfolio, df_returns, series_portfolio_returns = portfolio_return(df_portfolio, df_returns, array_weights)\n",
    "df_cov = covariance_matrix(dict_assets, df_returns)\n",
    "portfolio_variance = portfolio_variance_calculator(df_cov, array_weights)\n",
    "std = portfolio_std(portfolio_variance)\n",
    "Pret = portfolio_mean_return(mean_returns, array_weights)\n",
    "Var_Parametric(Pret, std, \"normal\")\n",
    "CVar_Parametric(Pret, std, \"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
